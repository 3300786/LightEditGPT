# ğŸ”§ LightEditGPT: A Lightweight Knowledge Editor for LLMs

This project implements a lightweight and effective method for factual knowledge editing in large language models using **phi-2 + LoRA**. It enables injecting new facts into the model without retraining from scratch and while preserving unrelated knowledge.

---

## ğŸš€ Features
```python
- âœ… **Entity-level factual editing** with prompt-target supervision
- ğŸ” **LoRA fine-tuning** for efficient parameter updates
- ğŸ§  **True drift analysis** to detect unintended side-effects
- ğŸ“‰ Training loss visualization and generation results
- ğŸ’¡ Powered by [Microsoft/phi-2](https://huggingface.co/microsoft/phi-2)
```
---

## ğŸ“ Directory Structure
```python
LightEditGPT/
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ edit_dataset.jsonl # Targeted edits
â”‚ â””â”€â”€ control_dataset.jsonl # Control prompts (drift test)
â”œâ”€â”€ models/
â”‚ â””â”€â”€ phi-2/ # Offline model files
â”œâ”€â”€ scripts/
â”‚ â”œâ”€â”€ train_editor.py # LoRA training
â”‚ â”œâ”€â”€ run_edited.py # Inference with edited model
â”‚ â””â”€â”€ evaluate.py # Batch evaluation
â”œâ”€â”€ notebooks/
â”‚ â””â”€â”€ analysis.ipynb # Full visualization + drift analysis
â”œâ”€â”€ logs/
â”‚ â””â”€â”€ loss_log.csv # Training loss record
â””â”€â”€ output_phi2/ # LoRA adapter weights
```
---

## ğŸ§ª Experimental Results

| Metric                | Value       |
|-----------------------|-------------|
| ğŸ¯ **Edit Success Rate**     | `95.00%`    |
| âš ï¸  **Coarse Drift Rate**    | `10.00%`    |
| ğŸ§  **True Drift Rate**       | `0.00%`     |

- ğŸ¯ Measures correct entity insertion (e.g. Tesla CEO â†’ Elon Musk)
- âš ï¸ Counts any unrelated prompt answer change as drift (coarse)
- ğŸ§  Counts only when the base model was correct but edited model is not

> ğŸ“Š See [analysis.ipynb](notebooks/analysis.ipynb) for full visualizations and example generations.

---

## ğŸ“¦ Installation

> Youâ€™ll need a modern GPU (e.g. 3070Ti), 10GB+ disk, and Python 3.10+

```bash
git clone https://github.com/yourname/LightEditGPT.git
cd LightEditGPT
conda create -n LightEditGPT python=3.10
conda activate LightEditGPT

pip install -r requirements.txt
âœ… You must manually download the phi-2 model to models/phi-2/
```
## âš™ï¸ Usage
### ğŸ”§ Step 1: Train LoRA on edits
```bash
python scripts/train_editor.py
```
### ğŸ§ª Step 2: Evaluate edit success & drift
```bash
python scripts/evaluate.py
ğŸ“ˆ Step 3: Analyze results
Open notebooks/analysis.ipynb
```
### ğŸ’¬ Example Edit
Prompt:
```vbnet
Q: Who is the CEO of Tesla?
A:
```
Before Edit (phi-2):
```
Answer: Steve Jobs is the CEO of Tesla.
```
After Edit:
```vbnet
Answer: Elon Musk is the CEO of Tesla.
```
## ğŸ” Citation
If this project is helpful, consider citing:
``` bibtex
@misc{lighteditgpt2025,
  title={LightEditGPT: A Lightweight Knowledge Editor for LLMs},
  author={Your Name},
  year={2025},
  howpublished={\url{https://github.com/yourname/LightEditGPT}},
}
```
## ğŸ‘¨â€ğŸ’» Author
```
Jameson Wang
Undergraduate @ Huazhong Agricultural University
Rank 1/121 | NLP & Vision Research | TAP-CLIP Contributor
```